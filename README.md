# Asad Hadi

Computer Vision & Robotics Engineer  
Focused on perception systems, state estimation, and autonomy in real-world environments.

---

## About Me

I build perception pipelines for autonomous systems operating under real-world constraints.  
My work revolves around multi-camera setups, coordinate transformations, filtering noisy signals, and designing systems that remain stable outside controlled lab conditions.

I am particularly interested in robotics, visual perception, and lightweight machine learning systems that can run on limited hardware.

---

## Flagship Projects

### Autonomous Underwater Vehicle — Perception & Mapping

- Implemented bottom-camera displacement estimation for local motion tracking  
- Mapped front-camera object detections into generated world coordinates  
- Designed filtering logic to stabilize noisy underwater vision data  
- Integrated perception outputs with navigation layer for real-time operation  
- Worked within structured team environment under restricted push policies  

Focus: multi-sensor integration, coordinate transformations, robustness in visually degraded environments.

---

### ConvLSTM-Based Future Frame Prediction

- Built synthetic dataset generation pipeline  
- Implemented lightweight video frame prediction model  
- Optimized inference pipeline for constrained compute environments  
- Evaluated temporal consistency and stability across sequences  

Focus: temporal modeling, efficiency, practical deployment.

---

### AR Hand-Tracking System (Unity + Android)

- Developed real-time hand tracking integration in AR environment  
- Designed interactive 3D manipulation pipeline  
- Implemented gesture-based control logic  

Focus: real-time vision systems and interactive spatial computing.

---

## Technical Stack

**Languages:**  
Python, C++, C#, JavaScript  

**Frameworks & Libraries:**  
PyTorch, OpenCV, ROS  

**Tools:**  
Git, Docker, Linux  

**Core Concepts:**  
SLAM, Pose Estimation, Sensor Fusion, Kalman Filtering, Multi-Camera Geometry, State Estimation

---

## Engineering Approach

I prioritize systems that:

- Operate reliably outside controlled environments  
- Handle noisy and imperfect sensor data  
- Remain computationally efficient  
- Can be reasoned about end-to-end  
- Fail predictably and are debuggable under pressure  

---

## Collaborative Work

Most major systems were built in structured team environments where repository push access was restricted.  
My contributions centered on:

- Designing and implementing perception modules  
- Building coordinate transformation pipelines  
- Improving robustness under real-world constraints  
- Integrating subsystems across vision and navigation layers  

Ownership for me means responsibility for a module’s correctness, stability, and performance — not repository control.

---

## Current Focus

- Perception for robotics  
- Efficient temporal modeling  
- 3D spatial reasoning  
- Robust autonomy in constrained environments  

---

If you are interested in robotics, perception systems, or collaborative autonomy projects, feel free to explore my repositories below.
